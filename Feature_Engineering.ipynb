{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 1: What is a parameter?**\n",
        "\n",
        "**Definition:**  \n",
        "In statistics and machine learning, a **parameter** is a numerical value that defines a characteristic of a population or a model.  \n",
        "\n",
        "#### üìå In Different Contexts:\n",
        "- **In statistics:** A parameter represents a fixed, unknown value (like population mean `Œº` or population standard deviation `œÉ`) that you are trying to estimate.\n",
        "- **In machine learning:** Parameters are internal variables the model learns during training (e.g., weights and biases in neural networks or coefficients in linear regression).\n",
        "\n",
        "#### üîç Example in Machine Learning:\n",
        "In **linear regression**, the model is:\n",
        "```\n",
        "y = w*x + b\n",
        "```\n",
        "Here:\n",
        "- `w` (weight) and `b` (bias) are **parameters** learned during training.\n",
        "- The model tries different values of `w` and `b` to minimize the error between predicted and actual values.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 2: What is correlation?**\n",
        "\n",
        "**Definition:**  \n",
        "**Correlation** measures the strength and direction of a linear relationship between two variables.  \n",
        "\n",
        "#### üîë Key Points:\n",
        "- Correlation values range between **-1 and +1**.\n",
        "- **+1:** Perfect positive correlation  \n",
        "- **0:** No linear correlation  \n",
        "- **-1:** Perfect negative correlation  \n",
        "\n",
        "#### ‚úÖ Types of Correlation:\n",
        "| Type              | Description                                      |\n",
        "|-------------------|--------------------------------------------------|\n",
        "| Positive          | Both variables increase together                 |\n",
        "| Negative          | One increases, the other decreases               |\n",
        "| Zero (None)       | No relationship                                  |\n",
        "\n",
        "#### üìä Example:\n",
        "Let‚Äôs say you have:\n",
        "- Hours studied vs. Exam score ‚Üí Positive correlation.\n",
        "- Time spent watching TV vs. Exam score ‚Üí Negative correlation.\n",
        "\n",
        "In Python:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "data = {'Hours': [1, 2, 3, 4], 'Score': [30, 50, 60, 80]}\n",
        "df = pd.DataFrame(data)\n",
        "print(df.corr())\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 3: What does negative correlation mean?**\n",
        "\n",
        "**Definition:**  \n",
        "A **negative correlation** means that as one variable increases, the other **decreases**.\n",
        "\n",
        "#### üìâ Example:\n",
        "- As **screen time** increases, **quality of sleep** might decrease.\n",
        "- Correlation coefficient could be something like `-0.8`, indicating a strong negative correlation.\n",
        "\n",
        "#### üîç Real-life example:\n",
        "Let‚Äôs say in a dataset:\n",
        "```plaintext\n",
        "Study Hours:   [8, 6, 4, 2]\n",
        "TV Time:       [1, 2, 3, 5]\n",
        "```\n",
        "As **Study Hours** decrease, **TV Time** increases ‚Üí Negative correlation.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 4: Define Machine Learning. What are the main components in Machine Learning?**\n",
        "\n",
        "**Definition:**  \n",
        "**Machine Learning (ML)** is a branch of Artificial Intelligence (AI) that allows systems to learn from data and improve over time without being explicitly programmed.\n",
        "\n",
        "---\n",
        "\n",
        "### üì¶ **Main Components of Machine Learning:**\n",
        "\n",
        "| Component           | Description                                                                 |\n",
        "|---------------------|-----------------------------------------------------------------------------|\n",
        "| **Data**            | The input ‚Äî examples with or without labels.                                |\n",
        "| **Features**        | The attributes used by the model to make predictions.                       |\n",
        "| **Model**           | The algorithm that learns patterns from data.                               |\n",
        "| **Parameters**      | Internal variables updated during training (like weights in neural nets).   |\n",
        "| **Training**        | The process of feeding data into the model to learn.                        |\n",
        "| **Loss Function**   | A function that tells how wrong the model is (how far off the predictions are). |\n",
        "| **Optimizer**       | An algorithm to minimize the loss function.                                 |\n",
        "| **Evaluation**      | Measure model performance on unseen/test data.                              |\n",
        "\n",
        "#### üîç Example:\n",
        "In a spam detector:\n",
        "- **Data:** Emails (labeled as spam/ham)\n",
        "- **Features:** Words, punctuation frequency, email length\n",
        "- **Model:** Naive Bayes\n",
        "- **Evaluation:** Accuracy, Precision, Recall on test set\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 5: How does loss value help in determining whether the model is good or not?**\n",
        "\n",
        "**Definition:**  \n",
        "A **loss value** is a number that represents how far the model‚Äôs predictions are from the actual values. Lower the loss, better the model (generally).\n",
        "\n",
        "---\n",
        "\n",
        "### üìä Why Loss is Important:\n",
        "- **Training Goal:** Minimize the loss function.\n",
        "- **Model Comparison:** Models with lower loss are preferred.\n",
        "- **Early Warning:** If loss stops decreasing ‚Üí Model may be overfitting or underfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Common Loss Functions:\n",
        "| Function           | Used For                        |\n",
        "|--------------------|----------------------------------|\n",
        "| Mean Squared Error | Regression tasks                |\n",
        "| Cross-Entropy      | Classification tasks            |\n",
        "\n",
        "---\n",
        "\n",
        "### üîç Example in Python:\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X = [[1], [2], [3]]\n",
        "y = [2, 4, 6]\n",
        "model = LinearRegression().fit(X, y)\n",
        "pred = model.predict(X)\n",
        "loss = mean_squared_error(y, pred)\n",
        "print(\"Loss:\", loss)\n",
        "```\n",
        "\n",
        "If `loss = 0`, it means predictions were perfect!\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "G5HHCkn206JO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 6: What are continuous and categorical variables?**\n",
        "\n",
        "#### üî¢ **Continuous Variables**  \n",
        "These are numeric variables that can take an **infinite number of values** within a range.\n",
        "\n",
        "- Can be **measured**.\n",
        "- Have **decimal** values (usually).\n",
        "- Examples:\n",
        "  - Temperature (e.g., 36.5¬∞C)\n",
        "  - Height (e.g., 5.8 ft)\n",
        "  - Income (e.g., ‚Çπ52,000.75)\n",
        "\n",
        "#### üìä **Categorical Variables**  \n",
        "These are variables that represent **categories or labels**.\n",
        "\n",
        "- Can be **counted**, but not measured.\n",
        "- No inherent order (in nominal), or may have order (in ordinal).\n",
        "- Examples:\n",
        "  - Colors: Red, Green, Blue\n",
        "  - Gender: Male, Female\n",
        "  - Education: High School, Bachelor's, Master's (ordinal)\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 7: How do we handle categorical variables in Machine Learning? What are the common techniques?**\n",
        "\n",
        "Machine learning models work with numbers. So, we need to **convert categorical variables into numerical format**.\n",
        "\n",
        "---\n",
        "\n",
        "### üîß **Common Techniques:**\n",
        "\n",
        "#### 1. **Label Encoding**  \n",
        "- Converts categories to integers.  \n",
        "- Example:\n",
        "  - `[\"Male\", \"Female\"]` ‚Üí `[1, 0]`\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "data['Gender'] = le.fit_transform(data['Gender'])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. **One-Hot Encoding**  \n",
        "- Creates **binary columns** for each category.\n",
        "- Avoids implying any order between categories.\n",
        "\n",
        "```python\n",
        "pd.get_dummies(data['Color'], prefix='Color')\n",
        "```\n",
        "If `Color = [\"Red\", \"Blue\", \"Green\"]`, it becomes:\n",
        "```\n",
        "Color_Blue  Color_Green  Color_Red\n",
        "     0           0            1\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### 3. **Ordinal Encoding**  \n",
        "- Useful for categories with **order**, like:\n",
        "  - Small < Medium < Large\n",
        "- Map manually or use `OrdinalEncoder`.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 8: What do you mean by training and testing a dataset?**\n",
        "\n",
        "In machine learning, we **split the data** into two or more parts:\n",
        "\n",
        "---\n",
        "\n",
        "### üìö **1. Training Set**\n",
        "- Used to **train the model** (fit the algorithm).\n",
        "- The model ‚Äúlearns‚Äù patterns in this data.\n",
        "\n",
        "---\n",
        "\n",
        "### üß™ **2. Testing Set**\n",
        "- Used to **evaluate** model performance.\n",
        "- Helps verify if the model can **generalize** to new, unseen data.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ö†Ô∏è Why It's Important:\n",
        "Without a test set, the model might just **memorize** the training data (overfitting) and perform poorly on new data.\n",
        "\n",
        "---\n",
        "\n",
        "#### üîç Example:\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 9: What is sklearn.preprocessing?**\n",
        "\n",
        "`sklearn.preprocessing` is a **module** in Scikit-learn that provides functions to **prepare your data** before fitting it to a model.\n",
        "\n",
        "---\n",
        "\n",
        "### üîß **Key Functions:**\n",
        "\n",
        "| Function                 | Purpose                          |\n",
        "|--------------------------|----------------------------------|\n",
        "| `StandardScaler`         | Feature scaling (mean = 0, std = 1) |\n",
        "| `MinMaxScaler`           | Scales features between 0 and 1 |\n",
        "| `LabelEncoder`           | Converts categorical labels to numbers |\n",
        "| `OneHotEncoder`          | Converts categories to binary columns |\n",
        "| `PolynomialFeatures`     | Adds polynomial terms (e.g., x¬≤, x¬≥) |\n",
        "| `Binarizer`              | Converts numerical data to binary (0/1) |\n",
        "\n",
        "---\n",
        "\n",
        "#### üîç Example:\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 10: What is a Test set?**\n",
        "\n",
        "The **Test Set** is a portion of the dataset used to **evaluate the final model** after training.\n",
        "\n",
        "---\n",
        "\n",
        "### üìä Characteristics:\n",
        "- The model does **not see this data during training**.\n",
        "- Gives an **unbiased estimate** of performance.\n",
        "- Helps detect **overfitting** or **underfitting**.\n",
        "\n",
        "---\n",
        "\n",
        "#### üîç Example:\n",
        "If your dataset has 1,000 rows:\n",
        "- 800 ‚Üí Training set\n",
        "- 200 ‚Üí Test set\n",
        "\n",
        "You train the model on the 800 rows and test how it performs on the 200 unseen rows.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "aKX11pu6097O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 11: How do we split data for model fitting (training and testing) in Python?**\n",
        "\n",
        "To **split the dataset** into training and testing subsets, we commonly use the `train_test_split()` function from **Scikit-learn**.\n",
        "\n",
        "---\n",
        "\n",
        "### üßÆ **Basic Syntax:**\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üßæ **Parameters Explained:**\n",
        "- `X`: Features (independent variables)\n",
        "- `y`: Target (dependent variable)\n",
        "- `test_size=0.2`: 20% of data goes to the test set, 80% to the train set\n",
        "- `random_state`: Ensures consistent split every time the code runs\n",
        "\n",
        "---\n",
        "\n",
        "### üîÑ **Visual Split Example:**\n",
        "\n",
        "| Dataset | Split | Description            |\n",
        "|---------|-------|------------------------|\n",
        "| X       | X_train | Data used for training |\n",
        "|         | X_test  | Data used for testing  |\n",
        "| y       | y_train | Target for training    |\n",
        "|         | y_test  | Target for testing     |\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 12: How do you approach a Machine Learning problem?**\n",
        "\n",
        "A systematic and strategic approach ensures better results. Here‚Äôs a typical **workflow**:\n",
        "\n",
        "---\n",
        "\n",
        "### üîÅ **Machine Learning Workflow:**\n",
        "\n",
        "1. **Problem Understanding**\n",
        "   - Define objective (classification? regression?)\n",
        "   - Understand domain & expectations\n",
        "\n",
        "2. **Data Collection**\n",
        "   - Collect structured or unstructured data from APIs, databases, CSVs, etc.\n",
        "\n",
        "3. **Exploratory Data Analysis (EDA)**\n",
        "   - Understand data patterns\n",
        "   - Detect missing values, outliers, distributions\n",
        "\n",
        "4. **Preprocessing**\n",
        "   - Handle missing values\n",
        "   - Encode categorical variables\n",
        "   - Feature scaling\n",
        "\n",
        "5. **Split Data**\n",
        "   - Train-test split\n",
        "\n",
        "6. **Model Selection**\n",
        "   - Choose algorithm: Linear Regression, Decision Tree, SVM, etc.\n",
        "\n",
        "7. **Training the Model**\n",
        "   - Use `.fit()` method to train on training data\n",
        "\n",
        "8. **Evaluation**\n",
        "   - Test on test set using metrics: accuracy, RMSE, F1-score\n",
        "\n",
        "9. **Hyperparameter Tuning**\n",
        "   - Use GridSearchCV or RandomizedSearchCV\n",
        "\n",
        "10. **Deployment**\n",
        "    - Export model (pickle/joblib)\n",
        "    - Deploy via API or web app\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 13: Why do we have to perform EDA before fitting a model to the data?**\n",
        "\n",
        "**EDA (Exploratory Data Analysis)** is essential because it **reveals the hidden structure and patterns** in data, helping make better modeling decisions.\n",
        "\n",
        "---\n",
        "\n",
        "### üîç **Key Reasons to Perform EDA:**\n",
        "\n",
        "1. **Detect Data Quality Issues**\n",
        "   - Missing values\n",
        "   - Outliers\n",
        "   - Duplicates\n",
        "\n",
        "2. **Understand Feature Relationships**\n",
        "   - Correlation between variables\n",
        "   - Target feature associations\n",
        "\n",
        "3. **Determine Variable Types**\n",
        "   - Categorical vs Continuous\n",
        "   - Appropriate preprocessing techniques\n",
        "\n",
        "4. **Visualize Data Distributions**\n",
        "   - Histograms, box plots, scatter plots\n",
        "\n",
        "5. **Improve Model Choice**\n",
        "   - Decide which algorithms or transformations to use\n",
        "\n",
        "---\n",
        "\n",
        "### üìä **Example:**\n",
        "```python\n",
        "import seaborn as sns\n",
        "sns.heatmap(df.corr(), annot=True)\n",
        "```\n",
        "This helps identify which variables are strongly correlated before applying the model.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 14: What is correlation?**\n",
        "\n",
        "**Correlation** is a statistical measure that indicates the **degree and direction** of relationship between two variables.\n",
        "\n",
        "---\n",
        "\n",
        "### üîÑ **Types of Correlation:**\n",
        "\n",
        "| Type         | Value Range | Meaning                             |\n",
        "|--------------|-------------|-------------------------------------|\n",
        "| Positive     | 0 to +1      | As X increases, Y also increases    |\n",
        "| Negative     | -1 to 0      | As X increases, Y decreases         |\n",
        "| Zero         | 0            | No linear relationship              |\n",
        "\n",
        "---\n",
        "\n",
        "### üß™ **Mathematical Formula (Pearson's r):**\n",
        "\\[\n",
        "r = \\frac{\\text{cov}(X, Y)}{\\sigma_X \\cdot \\sigma_Y}\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "### üìå **Example:**\n",
        "If height and weight have a correlation of 0.9, they are **strongly positively correlated**.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 15: What does negative correlation mean?**\n",
        "\n",
        "**Negative correlation** means that as **one variable increases**, the **other decreases**.\n",
        "\n",
        "---\n",
        "\n",
        "### üìâ **Interpreting Negative Correlation:**\n",
        "- Correlation coefficient (r) is **less than 0**, down to -1.\n",
        "- Indicates an **inverse relationship**.\n",
        "\n",
        "---\n",
        "\n",
        "### üìä **Examples:**\n",
        "\n",
        "1. **Temperature vs. Sweater Sales**\n",
        "   - As temperature rises, sweater sales fall.\n",
        "   - Correlation: -0.85 (strong negative)\n",
        "\n",
        "2. **Speed vs. Travel Time**\n",
        "   - As speed increases, travel time decreases.\n",
        "   - Correlation: -0.90\n",
        "\n",
        "---\n",
        "\n",
        "### üìå **Visualization:**\n",
        "A **scatter plot** showing a downward slope from left to right typically represents negative correlation.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "hLC-Dzt21H5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 16: How can you find correlation between variables in Python?**\n",
        "\n",
        "In Python, we commonly use **Pandas** or **NumPy** to calculate the correlation between variables.\n",
        "\n",
        "---\n",
        "\n",
        "### üß™ **Methods to Find Correlation:**\n",
        "\n",
        "1. **Using `pandas.DataFrame.corr()`**\n",
        "   - Calculates the **Pearson correlation coefficient** by default.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'height': [160, 170, 180, 150, 175],\n",
        "    'weight': [55, 65, 80, 50, 70]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df.corr())\n",
        "```\n",
        "\n",
        "2. **Using Seaborn Heatmap for visualization:**\n",
        "\n",
        "```python\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "3. **Using NumPy for individual correlation:**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "np.corrcoef(df['height'], df['weight'])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üìå Output Example:\n",
        "```\n",
        "            height   weight\n",
        "height     1.000     0.982\n",
        "weight     0.982     1.000\n",
        "```\n",
        "This shows a **strong positive correlation (0.98)** between height and weight.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 17: What is causation? Explain the difference between correlation and causation with an example.**\n",
        "\n",
        "---\n",
        "\n",
        "### üîç **Definition:**\n",
        "- **Causation** means **one variable directly affects another**.\n",
        "- **Correlation** just means they move together, but **does not prove a cause-effect** relationship.\n",
        "\n",
        "---\n",
        "\n",
        "### üß† **Key Differences:**\n",
        "\n",
        "| Aspect       | Correlation                           | Causation                             |\n",
        "|--------------|----------------------------------------|----------------------------------------|\n",
        "| Definition   | Statistical relationship               | Direct cause-effect relationship       |\n",
        "| Direction    | May go either way                      | Has a clear direction of influence     |\n",
        "| Proof        | Does not imply causality               | Implies causality                      |\n",
        "\n",
        "---\n",
        "\n",
        "### üìä **Example:**\n",
        "- **Correlation:** Ice cream sales and drowning cases increase in summer.\n",
        "- **Reality:** Both are influenced by **temperature**, but one **doesn‚Äôt cause** the other.\n",
        "\n",
        "- **Causation Example:**\n",
        "   - Smoking ‚ûú Lung cancer (smoking causes cancer, so there‚Äôs causation)\n",
        "\n",
        "---\n",
        "\n",
        "### üö® Warning:\n",
        "**‚ÄúCorrelation does not imply causation‚Äù** is a core principle in statistics.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 18: What is an Optimizer? What are different types of optimizers? Explain each with an example.**\n",
        "\n",
        "---\n",
        "\n",
        "### üß† **What is an Optimizer?**\n",
        "\n",
        "An **optimizer** is an algorithm used in **training machine learning models** (especially neural networks) to **adjust weights** to **minimize loss**.\n",
        "\n",
        "---\n",
        "\n",
        "### üõ†Ô∏è **Common Optimizers in ML:**\n",
        "\n",
        "| Optimizer | Description | Example |\n",
        "|----------|-------------|---------|\n",
        "| **SGD (Stochastic Gradient Descent)** | Updates weights using one data point at a time | Good for large datasets |\n",
        "| **Momentum** | Adds momentum to SGD to accelerate learning | Faster convergence |\n",
        "| **Adagrad** | Adapts learning rate for each parameter | Good for sparse data |\n",
        "| **RMSprop** | Normalizes gradients using moving average | Works well for RNNs |\n",
        "| **Adam** | Combines Momentum + RMSprop | Most commonly used |\n",
        "\n",
        "---\n",
        "\n",
        "### üìå **Example using Adam in TensorFlow/Keras:**\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "```\n",
        "\n",
        "Adam adapts learning rate **during training**, which helps in faster and smoother convergence.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 19: What is sklearn.linear_model?**\n",
        "\n",
        "---\n",
        "\n",
        "### üèóÔ∏è **Definition:**\n",
        "\n",
        "`sklearn.linear_model` is a module in **Scikit-learn** that provides **linear models** for **regression and classification tasks**.\n",
        "\n",
        "---\n",
        "\n",
        "### üîß **Common Classes in `linear_model`:**\n",
        "\n",
        "1. **LinearRegression()**\n",
        "   - Used for simple and multiple linear regression.\n",
        "\n",
        "2. **LogisticRegression()**\n",
        "   - Used for classification problems.\n",
        "\n",
        "3. **Ridge()**, **Lasso()**\n",
        "   - Regularized linear models to prevent overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### üß™ **Example: Linear Regression**\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "This fits a straight line that minimizes the difference between actual and predicted values.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 20: What does `model.fit()` do? What arguments must be given?**\n",
        "\n",
        "---\n",
        "\n",
        "### üß† **Definition:**\n",
        "\n",
        "The `.fit()` method is used to **train** or **fit the model** using the **training data**.\n",
        "\n",
        "---\n",
        "\n",
        "### üßæ **Syntax:**\n",
        "\n",
        "```python\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üìå **Arguments:**\n",
        "- `X_train`: Feature matrix (independent variables)\n",
        "- `y_train`: Target vector (dependent variable)\n",
        "\n",
        "---\n",
        "\n",
        "### üîÑ **What It Does:**\n",
        "- Calculates best parameters (like slope & intercept in linear regression)\n",
        "- Stores learned information in the model object for prediction\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **Example:**\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit([[1], [2], [3]], [2, 4, 6])\n",
        "```\n",
        "\n",
        "The model learns the **relationship y = 2x**, and can now make predictions.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "pj2sviBE1OhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 21: What does `model.predict()` do? What arguments must be given?**\n",
        "\n",
        "---\n",
        "\n",
        "### üîç **Definition:**\n",
        "\n",
        "`.predict()` is a method used after fitting a model. It **generates output (predictions)** from the model using **new/unseen data**.\n",
        "\n",
        "---\n",
        "\n",
        "### üìå **Syntax:**\n",
        "\n",
        "```python\n",
        "model.predict(X_test)\n",
        "```\n",
        "\n",
        "- `X_test`: The feature set (independent variables) for which we want to predict outcomes.\n",
        "\n",
        "---\n",
        "\n",
        "### üß™ **Example:**\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit([[1], [2], [3]], [2, 4, 6])  # learns y = 2x\n",
        "\n",
        "predictions = model.predict([[4], [5]])\n",
        "print(predictions)  # Output: [8. 10.]\n",
        "```\n",
        "\n",
        "The model uses the trained relationship to predict values for x = 4 and x = 5.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 22: What are continuous and categorical variables?**\n",
        "\n",
        "---\n",
        "\n",
        "### üìä **1. Continuous Variables:**\n",
        "- Can take **any numeric value** within a range.\n",
        "- Example: height, weight, temperature, salary\n",
        "\n",
        "üß™ Example:\n",
        "```python\n",
        "height = [150.2, 160.5, 172.0, 165.7]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üî† **2. Categorical Variables:**\n",
        "- Represent categories or labels.\n",
        "- Cannot be measured numerically (but can be encoded).\n",
        "- Example: gender, color, product category\n",
        "\n",
        "üß™ Example:\n",
        "```python\n",
        "gender = ['male', 'female', 'female', 'male']\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üìå **Key Differences:**\n",
        "\n",
        "| Feature      | Continuous Variable     | Categorical Variable     |\n",
        "|--------------|--------------------------|----------------------------|\n",
        "| Type         | Numeric                  | Non-numeric (often)        |\n",
        "| Values       | Infinite possibilities   | Finite categories          |\n",
        "| Use in ML    | Can be used directly     | Must be encoded            |\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 23: What is feature scaling? How does it help in Machine Learning?**\n",
        "\n",
        "---\n",
        "\n",
        "### üß† **Definition:**\n",
        "Feature scaling is a technique to **normalize or standardize** the range of features so that they are on a **comparable scale**.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ùì **Why It‚Äôs Important:**\n",
        "- Many ML algorithms (e.g., KNN, SVM, Gradient Descent) are **sensitive to feature magnitudes**.\n",
        "- If features have different scales (like age in years vs. income in lakhs), the larger-scale feature dominates learning.\n",
        "\n",
        "---\n",
        "\n",
        "### üìè **Common Scaling Methods:**\n",
        "\n",
        "1. **Min-Max Scaling (Normalization):**\n",
        "   - Scales data between 0 and 1.\n",
        "\n",
        "2. **Standardization (Z-score scaling):**\n",
        "   - Converts values into number of standard deviations from the mean.\n",
        "\n",
        "---\n",
        "\n",
        "### üß™ **Example:**\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = [[100], [200], [300]]\n",
        "scaler = StandardScaler()\n",
        "scaled_X = scaler.fit_transform(X)\n",
        "print(scaled_X)\n",
        "```\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "U7GvLXIe10c5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ".\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 24: How do we perform scaling in Python?**\n",
        "\n",
        "---\n",
        "\n",
        "### üß™ **Feature Scaling using `sklearn.preprocessing`**\n",
        "\n",
        "Python‚Äôs `scikit-learn` library offers multiple ways to scale or normalize features.\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Standardization (Z-score scaling)**  \n",
        "- Scales the data to have **mean = 0** and **standard deviation = 1**.\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = [[1], [2], [3], [4], [5]]\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(X)\n",
        "print(scaled_data)\n",
        "```\n",
        "\n",
        "> Used when data has outliers or does not follow a strict 0-1 range.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Min-Max Scaling**\n",
        "- Scales features to a **[0, 1] range**.\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X = [[10], [20], [30], [40]]\n",
        "scaler = MinMaxScaler()\n",
        "scaled = scaler.fit_transform(X)\n",
        "print(scaled)\n",
        "```\n",
        "\n",
        "> Best when you want **bounded** feature ranges.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Robust Scaling**\n",
        "- Uses **median and interquartile range**.  \n",
        "- Ideal for **datasets with outliers**.\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "X = [[1], [100], [1000]]\n",
        "scaler = RobustScaler()\n",
        "print(scaler.fit_transform(X))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 25: What is `sklearn.preprocessing`?**\n",
        "\n",
        "---\n",
        "\n",
        "### üß† **Definition:**\n",
        "\n",
        "`sklearn.preprocessing` is a **module in Scikit-learn** that contains methods to **scale, normalize, encode, and transform** your data before feeding it to a model.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚öôÔ∏è **Main Functionalities:**\n",
        "\n",
        "| Functionality         | Method                     | Use Case                              |\n",
        "|-----------------------|----------------------------|----------------------------------------|\n",
        "| **Scaling**           | `StandardScaler`           | Standardize features                   |\n",
        "|                       | `MinMaxScaler`             | Normalize to 0‚Äì1 range                 |\n",
        "|                       | `RobustScaler`             | Use medians, robust to outliers        |\n",
        "| **Normalization**     | `Normalizer`               | Normalize rows to unit norm            |\n",
        "| **Encoding**          | `OneHotEncoder`, `LabelEncoder` | Encode categorical variables     |\n",
        "| **Binarization**      | `Binarizer`                | Convert values to 0/1 (thresholding)   |\n",
        "\n",
        "---\n",
        "\n",
        "### üß™ **Example: Encoding + Scaling**\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "# Encode categories\n",
        "le = LabelEncoder()\n",
        "encoded = le.fit_transform(['red', 'blue', 'green'])\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = MinMaxScaler()\n",
        "scaled = scaler.fit_transform([[10], [20], [30]])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 26: How do we split data for model fitting (training and testing) in Python?**\n",
        "\n",
        "---\n",
        "\n",
        "### üìä **Why Split?**\n",
        "Splitting ensures that we:\n",
        "- Train the model on one set (training data).\n",
        "- Evaluate on unseen data (test data) to check generalization.\n",
        "\n",
        "---\n",
        "\n",
        "### üß™ **Using `train_test_split` from `sklearn.model_selection`:**\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = [[1], [2], [3], [4], [5]]\n",
        "y = [10, 20, 30, 40, 50]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train X:\", X_train)\n",
        "print(\"Test X:\", X_test)\n",
        "```\n",
        "\n",
        "- `test_size=0.2` ‚Üí 20% for testing, 80% for training.\n",
        "- `random_state` ‚Üí ensures repeatability.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **QUESTION 27: Explain data encoding.**\n",
        "\n",
        "---\n",
        "\n",
        "### üß† **What is Data Encoding?**\n",
        "\n",
        "Data encoding is the process of **transforming categorical variables into numeric form** so that ML models can process them.\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ **Why Important?**\n",
        "Models cannot process strings like `\"red\"` or `\"yes\"`. They need numerical values.\n",
        "\n",
        "---\n",
        "\n",
        "### üîß **Common Encoding Techniques:**\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Label Encoding:**\n",
        "\n",
        "- Assigns **integer values** to each category.\n",
        "- Can introduce **ordinal relationships** where none exist.\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "data = ['cat', 'dog', 'dog', 'fish']\n",
        "encoded = le.fit_transform(data)\n",
        "print(encoded)  # [0 1 1 2]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. One-Hot Encoding:**\n",
        "\n",
        "- Converts categories into **binary vectors**.\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "data = np.array([['red'], ['green'], ['blue']])\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "one_hot = encoder.fit_transform(data)\n",
        "print(one_hot)\n",
        "```\n",
        "\n",
        "Output:\n",
        "```\n",
        "[[0. 0. 1.]\n",
        " [0. 1. 0.]\n",
        " [1. 0. 0.]]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Ordinal Encoding (when order matters):**\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "data = [['low'], ['medium'], ['high']]\n",
        "encoder = OrdinalEncoder(categories=[['low', 'medium', 'high']])\n",
        "print(encoder.fit_transform(data))\n",
        "```\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HPPkYzJI18H4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mmnguky501qZ"
      },
      "outputs": [],
      "source": []
    }
  ]
}